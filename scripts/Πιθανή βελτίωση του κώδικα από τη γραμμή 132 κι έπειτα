import pandas as pd
import numpy as np
import os
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb
import shap
import matplotlib.pyplot as plt

# Define file path
file_path = os.path.join(os.getcwd(), "data\QualityOfService5GDataset-3.csv")

# Check if file exists
if not os.path.isfile(file_path):
    print("File does not exist.")
    exit()

# Load data
data = pd.read_csv(file_path, dtype={'User_ID': 'string',
                                      'application_type': 'string',
                                      'signal_strength(dBm)': 'float64',
                                      'latency(msec)': 'int64',
                                      'required_bandwidth(Mbps)': 'int64',
                                      'allocated_bandwidth(Mbps)': 'int64',
                                      'resource_allocation': 'int64'})

# Data Preprocessing
y = data['latency(msec)'] 
X = data.drop(['User_ID', 'latency(msec)'], axis=1)

# One-hot encode 'application type'
X = pd.get_dummies(X, columns=['application_type'])

# Handle missing values
X = X.fillna(0)

# Min-Max scaling for numerical features
scaler = MinMaxScaler()
numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns
X[numerical_cols] = scaler.fit_transform(X[numerical_cols])

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# XGBoost Regressor with Hyperparameter Tuning
param_grid = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.1, 0.01, 0.001],
    'n_estimators': [100, 500, 1000],
    'colsample_bytree': [0.5, 0.8, 1.0]
}

xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
grid_search = GridSearchCV(xgb_model, param_grid, cv=10, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)

best_model = grid_search.best_estimator_
best_params = grid_search.best_params_

print("Best Hyperparameters:", best_params)

# Evaluate model performance on the test set
y_pred = best_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Test MSE:", mse)
print("Test R^2:", r2)

# SHAP Analysis for Feature Importance
explainer = shap.Explainer(best_model)
shap_values = explainer(X_test)

# Visualize feature importance
shap.plots.bar(shap_values)
shap.summary_plot(shap_values, X_test)
